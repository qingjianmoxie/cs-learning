# encode()和decode()

## 前言：

我们知道，计算机是以二进制为单位的，也就是说计算机只识别0和1,也就是我们平时在电脑上看到的文字，只有先变成0和1，计算机才会识别它的意思。这种数据和二进制的转换规则就是编码。计算机的发展中，有ASCII码，GBK，Unicode，utf-8编码。我们先从编码的发展史了解一下编码的进化过程。

## 编码发展史

**ASCII码**
ASCII码是美国早期制定的编码规范，只能表示128个字符，包括英文字符、阿拉伯数字、西文字符以及32个控制字符。

**GB2312**
当国人得到计算机后，那就要对汉字进行编码。在ASCII码表的基础上，小于127的字符意义与原来相同；而将两个大于127的字节连在一起，来表示汉字，前一个字节从0xA1（161）到0xF7（247）共87个字节，称为高字节，后一个字节从0xA1（161）到0xFE（254）共94个字节，称为低字节，两者可组合出约8000种组合，用来表示6763个简体汉字、数学符号、罗马字母、日文字等。
在重新编码的数字、标点、字母是两字节长的编码，这些称为“全角”字符；而原来在ASCII码表的127以下的称为“半角”字符。
简单而言，GB2312就是在ASCII基础上的简体汉字扩展。

**GBK**
简单而言，GBK是对GB2312的进一步扩展（K是汉语拼音kuo zhan（扩展）中“扩”字的声母），
收录了21886个汉字和符号，完全兼容GB2312。

**GB18030**
GB18030收录了70244个汉字和字符，更加全面，与 GB 2312-1980 和 GBK 兼容。
GB18030支持少数民族的汉字，也包含了繁体汉字和日韩汉字。
其编码是单、双、四字节变长编码的。

**Unicode**
每个国家都像中国一样，把自己的语言编码，于是出现了各种各样的编码，如果你不安装相应的编码，就无法解释相应编码想表达的内容。
各自编码无法国际交流。一个国际组织一起创造了一种编码 UNICODE(Universal Multiple-Octet Coded Character Set)规定所有字符用两个字节表示，就是固定的，所有的字符就两个字节，计算机容易识别。2的16次方可以表示所有的字符了。
准确来说，Unicode不是编码格式，而是字符集。这个字符集包含了世界上目前所有的符号。

**UTF(UCS Transfer Format)**
UNICODE虽然解决了各自为战的问题，但是美国人不愿意了，因为美国原来的ASCII只需要一个字节就可以了。UNICODE编码却让他们的语言多了一个字节，白白浪费一个字节的存储空间。经过协商，出现了一种新的转换格式，被称为通用转换格式，也就是UTF(unicode transformation format).常见的有utf-8,utf-16。utf-8规定，先分类，美国字符一个字节，欧洲两个字符，东南亚三个字符。

## encode()和decode()

从英文意思上看, decode是解码，encode英文原意 编码
字符串在Python内部的表示是unicode编码，因此，在做编码转换时，通常需要以unicode作为中间编码， 即先将其他编码的字符串解码（decode）成unicode，再从unicode编码（encode）成另一种编码。即:

          decode                 encode
    str ---------> str(Unicode) ---------> str

decode的作用是将其他编码的字符串转换成unicode编码，如str1.decode('gb2312')，表示将gb2312编码的字符串str1转换成unicode编码。
encode的作用是将unicode编码转换成其他编码的字符串，如str2.encode('gb2312')，表示将unicode编码的字符串str2转换成gb2312编码。
总得意思:想要将其他的编码转换成utf-8必须先将其解码成unicode然后重新编码成utf-8,它是以unicode为转换媒介的 如：s='中文' 如果是在utf8的文件中，该字符串就是utf8编码，如果是在gb2312的文件中，则其编码为gb2312。这种情况下，要进行编码转换，都需要先用 decode方法将其转换成unicode编码，再使用encode方法将其转换成其他编码。通常，在没有指定特定的编码方式时，都是使用的系统默认编码创建的代码文件.
