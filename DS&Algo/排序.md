# 排序

所有排序的C语言实现, 为了规范统一一个格式:
void x_sort (ElementType A[], int N)
+ 大多数情况下，为简单起见，讨论从小到大的整数排序
+ 只讨论基于比较的排序（ > = < 有定义）
+ 只讨论内部排序
+ 稳定性：任意两个相等的数据, 排序前后的相对位置不发生改变

## 排序算法的比较

| 排序算法 | 平均时间复杂度 | 最坏情况下时间复杂度 | 额外空间复杂度 | 稳定性 |
| :-: | :-: | :-: | :-: | :-: |
| 冒泡排序 | O(N^2) | O(N^2) | O(1) | 稳定 |
| 插入排序 | O(N^2) | O(N^2) | O(1) | 稳定 |
| 选择排序 | O(N^2) | O(N^2) | O(1) | 不稳定 |
| 希尔排序 | O(N^d) | O(N^2) | O(1) | 不稳定 |
| 堆排序 | O(NlogN) | O(NlogN) | O(1) | 不稳定 |
| 快速排序 | O(NlogN) | O(N^2) | O(logN) | 不稳定 |
| 归并排序 | O(NlogN) | O(NlogN) | O(N) | 稳定 |
| 基数排序 | O(P(N+B)) | O(P(N+B)) | O(N+B) | 稳定 |

## 冒泡排序

冒泡排序在扫描过程中两两比较相邻记录，如果反序则交换，最终，最大记录就被“沉到”了序列的最后一个位置，第二遍扫描将第二大记录“沉到”了倒数第二个位置，重复上述操作，直到n-1 遍扫描后，整个序列就排好序了。

如果所有待排序的元素是存放在单向链表中的, 使用冒泡排序有优势.

冒泡排序是稳定的.

C实现:
    [bubble_sort.c](../code/bubble_sort.c)

## 选择排序

选择排序也是一种简单直观的排序算法。它的工作原理很容易理解：初始时在序列中找到最小（大）元素，放到序列的起始位置作为已排序序列；然后，再从剩余未排序元素中继续寻找最小（大）元素，放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。

注意选择排序与冒泡排序的区别：冒泡排序通过依次交换相邻两个顺序不合法的元素位置，从而将当前最小（大）元素放到合适的位置；而选择排序每遍历一次都记住了当前最小（大）元素的位置，最后仅需一次交换操作即可将其放到合适的位置。

C++实现:
    [selection_sort.cpp](../code/selection_sort/selection_sort.cpp)
    [Makefile](../code/selection_sort/Makefile)

GO实现:
    [selection_sort.go](../code/selection_sort/selection_sort.go)

python实现:
    [selection_sort.py](../code/selection_sort/selection_sort.py)

## 插入排序

直接插入排序（straight insertion sort），有时也简称为插入排序（insertion sort），是减治法的一种典型应用。其基本思想如下：

+ 对于一个数组A[0,n]的排序问题，假设认为数组在A[0,n-1]排序的问题已经解决了。
+ 考虑A[n]的值，从右向左扫描有序数组A[0,n-1]，直到第一个小于等于A[n]的元素，将A[n]插在这个元素的后面。

很显然，基于增量法的思想在解决这个问题上拥有更高的效率。

C实现:
    [insert_sort.c](../code/insert_sort.c)

## 时间复杂度下界

先思考一下给定初始序列{34, 8, 64, 51, 32, 21}，冒泡排序和插入排序分别需要多少次元素交换才能完成？

逆序对的定义:
对于下标`i < j`, 如果`A[i] > A[j]`，则称(i,j)是一对逆序对(inversion)

问题：序列{34, 8, 64, 51, 32, 21}中有多少逆序对？
答案: 有9个逆序对
+ 交换2个相邻元素正好消去1个逆序对！
+ 插入排序： T(N, I) = O(N+I)
    I表示序列中逆序对的个数.
所以如果序列基本有序，则插入排序简单且高效.

+ 定理：任意N个不同元素组成的序列平均具有`N(N-1)/4`个逆序对。
+ 定理：任何仅以交换**相邻**两元素来排序的算法，其平均时间复杂度为`Ω(N^2)`。

这意味着：要提高算法效率，我们必须:
+ 每次消去不止1个逆序对！
+ 每次交换相隔较远的2个元素！

## 希尔排序

希尔排序是希尔（Donald Shell）于1959年提出的一种排序算法。希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破O(n^2）的第一批算法之一。

定义增量序列 DM > DM-1 > … > D1 = 1
+ 对每个Dk 进行“Dk间隔”排序( k = M, M-1, … 1 )
+ 注意: "Dk-间隔"有序的序列，在执行"Dk-1间隔"排序后，仍然是"Dk间隔"有序的

原始希尔排序 DM = N / 2 , Dk = Dk+1 / 2

C实现:
    [shell_sort.c](../code/shell_sort.c)

## 堆排序

堆排序实际是对选择排序的一个改进.

C实现:
    [heap_sort.c](../code/heap_sort.c)

+ 定理：堆排序处理N个不同元素的随机排列的平均比较次数是`2NlogN - O(Nlog logN)`。
+ 虽然堆排序给出最佳平均时间复杂度，但实际效果不如用Sedgewick增量序列的希尔排序。

## 归并排序

归并排序（merge-sort）是利用**归并**的思想实现的排序方法，该算法采用经典的**分治**（divide-and-conquer）策略（分治法将问题**分**(divide)成一些小的问题然后递归求解，而**治**(conquer)的阶段则将分的阶段得到的各答案"修补"在一起，即分而治之)。

+ 递归算法

C实现:
    [heap_sort.c](../code/merge_sort_1.c)

+ 迭代算法

C实现:
    [heap_sort.c](../code/merge_sort_2.c)

归并排序是稳定的.

由于归并排序需要额外的空间, 所以在内部排序中基本不用, 主要用于外部排序.

## 快速排序

快速排序是一种常用的排序算法，比选择排序快得多。例如，C语言标准库中的函数qsort实现的就是快速排序。快速排序使用了分而治之的思想。分而治之(divide and conquer, D&C)是一种著名的递归式问题解决方法.

快速排序的伪码实现如下:

    void Quicksort(ElementType A[], int N)
    {
        if (N < 2) return;
        pivot = 从A[]中选一个主元;
        将s = {A[] \ pivot} 分成2个独立子集;
            A1 = {a属于S | a <= pivot} 和
            A2 = {a属于S | a > pivot};
        A[] = Quicksort(A1, N1) +
                        {pivot} +
              Quicksort(A2, N2);
    }

在实现中需要注意两个点, 如果处理不好, 快速排序会变得非常慢.

1. 如何选取主元
如果将主元设为第一个元素, 即pivot = A[0], 那么当元素是有序时, 快速排序的时间复杂度是O(N^2).
如果随机取pivot, 随机函数也不便宜.
经典的取法是取头、中、尾的中位数.

2. 如何将集合分为两个独立的子集

C实现:
    [quick_sort.c](../code/quick_sort/quick_sort.c)

## 基数排序

前面讲的几种排序算法都是基于比较大小来给元素排序的, 有一个定理是说, 仅仅基于比较大小的排序, 最坏时间复杂度的下界是O(NlogN). 有没有可能更快呢, 是有可能的, 这时我们除了比较大小, 还要干点别的事.
"次位优先" (Least Significant Digit)
"主位优先" (Most Significant Digit)

C实现:
    [LSDradix_sort.c](../code/LSDradix_sort.c)
    [MSDradix_sort.c](../code/MSDradix_sort.c)
