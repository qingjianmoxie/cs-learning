# 哈夫曼树(Huffman Tree)与哈夫曼编码

## 哈夫曼编码简介

哈夫曼编码（Huffman Coding）是一种编码方式，也称为“赫夫曼编码”，是David A. Huffman 1952年发明的一种构建极小多余编码的方法。
在计算机数据处理中，哈夫曼编码使用**变长编码表**对源符号进行编码，出现频率较高的源符号采用较短的编码，出现频率较低的符号采用较长的编码，使编码之后的字符串字符串的平均长度、期望值降低，以达到**无损压缩数据**的目的。

举个例子，现在我们有一字符串：

> this is an example of a huffman tree

这串字符串有36个字符，如果按普通方式存储这串字符串，每个字符占据1个字节，则共需要36 * 1 * 8 = 288bit。
经过分析我们发现，这串字符串中各字母出现的频率不同，如果我们能够按如下编码：

| 字母 | 频率 | 编码 | --- | 字母 | 频率 | 编码 |
| --- | --- | --- | --- | --- | --- | --- |
| space | 7 | 111 |  | s | 2 | 1011 |
| a | 4 | 010 |  | t | 2 | 0110 |
| e | 4 | 000 |  | l | 1 | 11001 |
| f | 3 | 1101 |  | o | 1 | 00110 |
| h | 2 | 1010 |  | p | 1 | 10011 |
| i | 2 | 1000 |  | r | 1 | 11000 |
| m | 2 | 0111 |  | u | 1 | 00111 |
| n | 2 | 0010 |  | x | 1 | 10010 |

编码这串字符串，只需要：
(7+4+4)x3 + (3+2+2+2+2+2+2)x4 + (1+1+1+1+1+1)x5 = 45+60+30 = 135bit
编码这串字符串只需要135bit！单单这串字符串，就压缩了288-135 = 153bit。

那么，我们如何获取每个字符串的编码呢？这就需要哈夫曼树了。
源字符编码的长短取决于其出现的频率，我们把源字符出现的频率定义为该字符的权值。

## 哈夫曼树简介

哈夫曼又称最优二叉树。是一种带权路径长度最短的二叉树。它的定义如下。

### 哈夫曼树的定义

假设有n个权值{w1,w2,w3,w4,...,wn}，构造一棵有n个节点的二叉树，若树的带权路径最小，则这颗树称作哈夫曼树。这里面涉及到几个概念，我们由一棵哈夫曼树来解释

          100               100
          / \               / \
        40   60            40  60
       / \   / \               / \
     10  20 30  30            30  30
                                  / \
                                 10  20
     树a:普通二叉树         树b:哈夫曼树

* **路径与路径长度**：从树中一个节点到另一个节点之间的分支构成了两个节点之间的路径，路径上的分支数目称作路径长度。若规定根节点位于第一层，则根节点到第H层的节点的路径长度为H-1.如树b：100到60 的路径长度为1；100到30的路径长度为2；100到20的路径长度为3。

* **树的路径长度**：从根节点到每一节点的路径长度之和。树a的路径长度为1+1+2+2+2+2 = 10；树b的路径长度为1+1+2+2+3+3 = 12.

* **节点的权**：将树中的节点赋予一个某种含义的数值作为该节点的权值，该值称为节点的权；

* **带权路径长度**：从根节点到某个节点之间的路径长度与该节点的权的乘积。例如树b中，节点10的路径长度为3,它的带权路径长度为10 * 3 = 30；

* **树的带权路径长度**：树的带权路径长度为所有叶子节点的带权路径长度之和，称为WPL。树a的WPL = 2*（10+20+30+30） = 180 ;树b的WPL = 1x40+2x30+3x10+3x20 = 190.而哈夫曼树就是**树的带权路径最小的二叉树**。

## 构造哈夫曼树

假设有n个权值，则构造出的哈夫曼树有n个**叶子节点**.n个权值记为{w1,w2,w3...wn},哈夫曼树的构造过程为：

1. 将w1,w2,w3...wn看成具有n棵树的森林，每棵树仅有一个节点。
2. 从森林中，选取两棵根节点权值最小的树，两棵树分别作为左子树与右子树，构建一棵新树。新树的权值等于左右子树权值之和。
3. 从森林中删除两棵权值最小的树，将构建完成后的新树加入森林中。
4. 重复2、3步骤，直到森林只剩一棵树为止。这棵树便是哈夫曼树。

图一的树b为一棵哈夫曼树，它的叶子节点为{10，20，30，40}，以这4个权值构建树b的过程为：
![image](https://images2015.cnblogs.com/blog/610439/201602/610439-20160201152525085-889446328.png)

[哈夫曼树](./src/Huffman/Huffman.h)
[哈弗曼树测试代码](./src/Huffman/Huffman.cc)

测试结果：

    当前结点：100.它的左孩子节点为：40.它的右孩子节点为：60.
    当前结点：40.它没有左孩子.它没有右孩子.
    当前结点：60.它的左孩子节点为：30.它的右孩子节点为：30.
    当前结点：30.它没有左孩子.它没有右孩子.
    当前结点：30.它的左孩子节点为：10.它的右孩子节点为：20.
    当前结点：10.它没有左孩子.它没有右孩子.
    当前结点：20.它没有左孩子.它没有右孩子.

根据节点关系可以画出如下二叉树，正是上面我们构建的哈夫曼树。

        100
        / \
      40   60
           / \
          30 30
          / \
         10 20

## 再看哈夫曼编码

为{10，20，30，40}这四个权值构建了哈夫曼编码后，我们可以由如下规则获得它们的哈夫曼编码：

* 从根节点到每一个叶子节点的路径上，左分支记为0，右分支记为1，将这些0与1连起来即为叶子节点的哈夫曼编码。如下图：

![image](https://images2015.cnblogs.com/blog/610439/201602/610439-20160201152559147-2030415684.png)

| （字母）权值 | 编码 |
| --- | --- |
| 10 | 100 |
| 20 | 101 |
| 30 | 11 |
| 40 | 0 |

由此可见，出现频率越高的字母（也即权值越大），其编码越短。这便使编码之后的字符串的平均长度、期望值降低，从而达到无损压缩数据的目的。

## 哈夫曼树的特点:
+ 没有度为1的结点；
+ 哈夫曼树的任意非叶节点的左右子树交换后仍是哈夫曼树；
+ n个叶子结点的哈夫曼树共有2n-1个结点；
+ 对同一组权值{w1 ,w2 , …… , wn}， 可能存在不同构的两棵哈夫曼树呢
